#!/usr/bin/env python
# -*- coding: utf-8 -*-

################################################################################
# Copyright 2018 ROBOTIS CO., LTD.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
################################################################################

# Authors: Leon Jung, Gilbert, Special Thanks : Roger Sacchelli

import rospy
import numpy as np
import cv2
from cv_bridge import CvBridge
from std_msgs.msg import UInt8, Float64, String
from sensor_msgs.msg import Image, CompressedImage
from dynamic_reconfigure.server import Server
from turtlebot3_autorace_detect.cfg import DetectLaneParamsConfig
import math
from geometry_msgs.msg import Twist

class DetectLane():
    def __init__(self):
        self.hue_white_l = rospy.get_param("~detect/lane/white/hue_l", 0)
        self.hue_white_h = rospy.get_param("~detect/lane/white/hue_h", 25)
        self.saturation_white_l = rospy.get_param("~detect/lane/white/saturation_l", 0)
        self.saturation_white_h = rospy.get_param("~detect/lane/white/saturation_h", 36)
        self.lightness_white_l = rospy.get_param("~detect/lane/white/lightness_l", 180)
        self.lightness_white_h = rospy.get_param("~detect/lane/white/lightness_h", 255)

        self.hue_yellow_l = rospy.get_param("~detect/lane/yellow/hue_l", 27)
        self.hue_yellow_h = rospy.get_param("~detect/lane/yellow/hue_h", 41)
        self.saturation_yellow_l = rospy.get_param("~detect/lane/yellow/saturation_l", 130)
        self.saturation_yellow_h = rospy.get_param("~detect/lane/yellow/saturation_h", 255)
        self.lightness_yellow_l = rospy.get_param("~detect/lane/yellow/lightness_l", 160)
        self.lightness_yellow_h = rospy.get_param("~detect/lane/yellow/lightness_h", 255)

        self.is_calibration_mode = rospy.get_param("~is_detection_calibration_mode", False)
        if self.is_calibration_mode == True:
            srv_detect_lane = Server(DetectLaneParamsConfig, self.cbGetDetectLaneParam)

        self.sub_image_type = "compressed"         # you can choose image type "compressed", "raw"
        self.pub_image_type = "raw"  # you can choose image type "compressed", "raw"

        if self.sub_image_type == "compressed":
            # subscribes compressed image
            self.sub_image_original = rospy.Subscriber('/detect/image_input/compressed', CompressedImage, self.cbFindLane, queue_size = 1)
            #print(1)#TEST
        elif self.sub_image_type == "raw":
            # subscribes raw image
            self.sub_image_original = rospy.Subscriber('/detect/image_input', Image, self.cbFindLane, queue_size = 1)
            #print(0)#TEST
        if self.pub_image_type == "compressed":
            # publishes lane image in compressed type 
            self.pub_image_lane = rospy.Publisher('/detect/image_output/compressed', CompressedImage, queue_size = 1)
            #print("COMPRESS")
        elif self.pub_image_type == "raw":
            # publishes lane image in raw type
            self.pub_image_lane = rospy.Publisher('/detect/image_output', Image, queue_size = 1)
            
            #print("RAW")
        if self.is_calibration_mode == True:
            if self.pub_image_type == "compressed":
                # publishes lane image in compressed type 
                self.pub_image_white_lane = rospy.Publisher('/detect/image_output_sub1/compressed', CompressedImage, queue_size = 1)
                self.pub_image_yellow_lane = rospy.Publisher('/detect/image_output_sub2/compressed', CompressedImage, queue_size = 1)
            elif self.pub_image_type == "raw":
                # publishes lane image in raw type
                self.pub_image_white_lane = rospy.Publisher('/detect/image_output_sub1', Image, queue_size = 1)
                self.pub_image_yellow_lane = rospy.Publisher('/detect/image_output_sub2', Image, queue_size = 1)
        
        self.pub_image_intersection = rospy.Publisher('/detect/intersection', Image, queue_size = 1)
        self.pub_lane = rospy.Publisher('/detect/lane', Float64, queue_size = 1)

        # subscribes state : yellow line reliability
        self.pub_yellow_line_reliability = rospy.Publisher('/detect/yellow_line_reliability', UInt8, queue_size=1)
 
        # subscribes state : white line reliability
        self.pub_white_line_reliability = rospy.Publisher('/detect/white_line_reliability', UInt8, queue_size=1)

        self.cvBridge = CvBridge()

        self.counter = 1
        self.img_len = 240 #########
        self.window_width = 1000.
        self.window_height = 600.

        self.reliability_white_line = 100
        self.reliability_yellow_line = 100
        self.commandSub = rospy.Subscriber("cmd", String, self.getsignal, queue_size = 1)
        self.twistPub = rospy.Publisher('/cmd_vel', Twist, queue_size=1)
        self.max_vel = 0.08 ####TUNE THIS PLZ!
        self.max_turn = 0.5 #####TUNE THIS PLZ!
        self.stop = True ##it was set To be false when true speed would be 0
        self.min_speed = 0.02 ####NEED TURN THIS
        self.frame_count = 0
        

    def cbGetDetectLaneParam(self, config, level):
        rospy.loginfo("[Detect Lane] Detect Lane Calibration Parameter reconfigured to")
        rospy.loginfo("hue_white_l : %d", config.hue_white_l)
        rospy.loginfo("hue_white_h : %d", config.hue_white_h)
        rospy.loginfo("saturation_white_l : %d", config.saturation_white_l)
        rospy.loginfo("saturation_white_h : %d", config.saturation_white_h)
        rospy.loginfo("lightness_white_l : %d", config.lightness_white_l)
        rospy.loginfo("lightness_white_h : %d", config.lightness_white_h)
        rospy.loginfo("hue_yellow_l : %d", config.hue_yellow_l)
        rospy.loginfo("hue_yellow_h : %d", config.hue_yellow_h)
        rospy.loginfo("saturation_yellow_l : %d", config.saturation_yellow_l)
        rospy.loginfo("saturation_yellow_h : %d", config.saturation_yellow_h)
        rospy.loginfo("lightness_yellow_l : %d", config.lightness_yellow_l)
        rospy.loginfo("lightness_yellow_h : %d", config.lightness_yellow_h)

        self.hue_white_l = config.hue_white_l
        self.hue_white_h = config.hue_white_h
        self.saturation_white_l = config.saturation_white_l
        self.saturation_white_h = config.saturation_white_h
        self.lightness_white_l = config.lightness_white_l
        self.lightness_white_h = config.lightness_white_h

        self.hue_yellow_l = config.hue_yellow_l
        self.hue_yellow_h = config.hue_yellow_h
        self.saturation_yellow_l = config.saturation_yellow_l
        self.saturation_yellow_h = config.saturation_yellow_h
        self.lightness_yellow_l = config.lightness_yellow_l
        self.lightness_yellow_h = config.lightness_yellow_h

        return config
    #the following section is going to test the image and see if the current hsv range is able to segment the lane
    def getDis(self,pointX,pointY,lineX1,lineY1,lineX2,lineY2):
        a=lineY2-lineY1
        b=lineX1-lineX2
        c=lineX2*lineY1-lineX1*lineY2
        dis=(math.fabs(a*pointX+b*pointY+c))/(math.pow(a*a+b*b,0.5))
        return dis
    def findsmall(self,test_list):
        K = 2
        res = sorted(range(len(test_list)), key = lambda sub: test_list[sub])[:K]
        return res
    
    def processimg(self,img):
        cs = img.shape
        #index = cs[0]/2+20 #<--FOR ONSITE
        #index = cs[0]/2 #<--FOR GAZEBO
        index = 0
        half = img[int(index):,:,:]
        gray = cv2.cvtColor(half,cv2.COLOR_BGR2GRAY)

        '''blur = cv2.medianBlur(half,5)
        hsv = cv2.cvtColor(blur, cv2.COLOR_BGR2HSV)
        lower_white = np.array([0, 0, 180])
        upper_white = np.array([25, 36 ,255])
        mask = cv2.inRange(hsv, lower_white, upper_white)
        resized_gray = cv2.cvtColor(blur,cv2.COLOR_BGR2GRAY)
        copy_img = resized_gray.copy()
        copy_img[mask==0]=0
        b = cv2.medianBlur(copy_img,5)'''
        ret,th_img = cv2.threshold(gray,0,255,cv2.THRESH_BINARY|cv2.THRESH_OTSU)
        ret,labels,stats,c= cv2.connectedComponentsWithStats(th_img)
        area = [s[4] for s in stats]
        del area[0]
        ind = area.index(max(area))+1
        for x in range(len(labels)):
            for y in range(len(labels[0])):
                if labels[x][y] == ind:
                    labels[x][y] = 255
                else:
                    labels[x][y] = 0

        #ret,th_img = cv2.threshold(b,0,255,cv2.THRESH_BINARY|cv2.THRESH_OTSU)
        copy = img.copy()  #TEST
        copy[0:int(index),:,:] = [0,0,0]
        #print(index)
        for i in range(labels.shape[0]):
                for j in range(labels.shape[1]):
                    if labels[i][j] != 0 :
                        copy[int(index)+i][j] = [0,255,255]
                    else:
                        copy[int(index)+i][j] = [0,0,0]
        #cv2.rectangle(copy, (20, 20), (100, 100), (0, 255, 0), 5)#test
        
        return copy

        '''edges = cv2.Canny(th_img,100,200)
        lines = cv2.HoughLines(edges,1,np.pi/180,10,1,50,50)
        if lines is None:
            return None
        line_ps = []
        for i in range(len(lines)):
            if i > 3:
                break
            for rho,theta in lines[i]:
                a = np.cos(theta)
                b = np.sin(theta)
                x0 = a*rho
                y0 = b*rho
                x1 = int(x0 + 1000*(-b))
                y1 = int(y0 + 1000*(a))
                x2 = int(x0 - 1000*(-b))
                y2 = int(y0 - 1000*(a))
                line_ps.append([x1,y1,x2,y2])
        dis = []
        for l in line_ps:
            dis.append(self.getDis(half.shape[1]/2,half.shape[0]/2,l[0],l[1],l[2],l[3]))
        small_index = self.findsmall(dis)
        exist_right = False 
        colored = False
        #check the two slopes with smallest index and see if there are any "right" and color the first left lane
        for s in small_index:
            slope = (line_ps[s][3]-line_ps[s][1])/(line_ps[s][2]-line_ps[s][0])
            if math.fabs(slope) < 0.1: # <-- Only consider extreme slope
                continue
            if slope <0 and not colored:#left
                colored = True
                
                cv2.line(half,(line_ps[s][0],line_ps[s][1]),(line_ps[s][2],line_ps[s][3]),(0,255,255),6)
            elif slope > 0:#right
                exist_right = True
        #print(exist_right)
        print(colored)
        copy = img.copy()
        if exist_right:
            copy[int(index):,:,:] = half
        else:
            for i in range(th_img.shape[0]):
                for j in range(th_img.shape[1]):
                    if th_img[i][j] != 0 :
                        copy[int(index)+i][j] = [0,255,255]
            print("curve")

        copy[int(index):,:,:] = half
        return copy'''
    def birdview(self,image):
        width = image.shape[1]
        #print(width)
        height = image.shape[0]
        # targeted rectangle on original image which needs to be transformed
        # tl = [45, 184]
        # tr = [262, 184]
        # br = [297,204]
        # bl = [2, 204]
        tl = [101, 134]
        tr = [206, 134]
        br = [281,171]
        bl = [3, 171]

        corner_points_array = np.float32([tl,tr,br,bl])

        # original image dimensions
        
        

        # Create an array with the parameters (the dimensions) required to build the matrix
        imgTl = [0,0]
        imgTr = [width,0]
        imgBr = [width,height]
        imgBl = [0,height]
        img_params = np.float32([imgTl,imgTr,imgBr,imgBl])

        # Compute and return the transformation matrix
        matrix = cv2.getPerspectiveTransform(corner_points_array,img_params)
        img_transformed = cv2.warpPerspective(image,matrix,(width,height))

        #cv2.imshow("IMgRAY",img_transformed)
        #cv2.waitKey()
        #cv2.destroyAllWindows()
        return img_transformed

    def extract_white(self,pic):
        ''''method1：使用inRange方法，拼接mask0,mask1'''
        #img2 = np.fromfile(pic, dtype=np.uint8)
        img = pic.copy()
        img_hsv = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)
        rows, cols, channels = img.shape

        # 区间1
        lower_red = np.array([0, 0, 151])
        upper_red = np.array([180, 33, 255])
        mask = cv2.inRange(img_hsv,lower_red,upper_red)
        # cv2.imshow('mask',mask)
        # 保存图片
        #cv2.imencode('.png', mask )[1].tofile(pic)
        kernel = np.ones((3,3),np.uint8)
        opening = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)
        # 区间1
        # lower_red = np.array([145, 31, 151])
        # upper_red = np.array([178, 112, 255])
        # mask0 = cv2.inRange(img_hsv,lower_red,upper_red)
        # opening0 = cv2.morphologyEx(mask0, cv2.MORPH_OPEN, kernel)
        # closing1 = cv2.morphologyEx(opening0, cv2.MORPH_CLOSE, kernel)
        # closing+=closing1
        # inverse = np.ones(closing.shape,dtype='uint8')*255
        # inverse -= closing
        # cv2.imshow('closing',closing)
        return closing

    def detect_intersection(self,cnt,shape):
        minRect = cv2.minAreaRect(cnt)
        box = cv2.boxPoints(minRect)
        box = np.int0(box)
        # cv2.imshow('pic',pic)
        # cv2.waitKey()
        # leftLane = np.ones(shape,dtype='uint8')*255
        # cv2.drawContours(leftLane,[box],0,(0,0,0),2)
        # cv2.imshow('box',leftLane)
        # cv2.waitKey()
        # print(box)
        LaneOrInterWidth = 20
        # the lane is flat, the length is longer than min width and the location is down
        if box[1][1]-box[2][1]<10 and box[2][0]-box[1][0]>LaneOrInterWidth and box[1][1]>170:
            return 'inter',box
        elif box[2][0]-box[1][0]>LaneOrInterWidth:
            return 'lane',box
        else:
            return 'continue',box

    def extract_left_lane(self,pic,image):
        height,width=pic.shape
        leftLane = np.zeros(pic.shape,dtype='uint8')
        leftLane[height//2+10:,:width//2] = 1
        leftLane *= pic
        _,contours,_ = cv2.findContours(leftLane,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)
        boundingBoxes = [(cv2.boundingRect(cnt),cv2.contourArea(cnt),cnt)for cnt in contours]
        boundingBoxes = sorted(boundingBoxes,key=lambda x:(x[0][1]+x[0][3],x[1]),reverse=True)
        # reduce noise
        copy = image.copy()
        reserveCnt = []
        for rect,area,cnt in boundingBoxes:
            # if len(reserveCnt)>0:
            #     break
            if area<200:
                continue
            else:
                # self.area.append(area)
                # print('minArea',min(self.area))
                interFlg,box = self.detect_intersection(cnt,pic.shape)
                if interFlg=='inter':
                    cv2.drawContours(copy,[cnt],-1,(0,255,0),-1)
                elif interFlg=='continue':
                    continue
                elif len(reserveCnt)<1:
                    reserveCnt = [cnt,box]
                    # break
        leftLane = np.ones(pic.shape,dtype='uint8')*255
        leftLane = cv2.cvtColor(leftLane,cv2.COLOR_GRAY2BGR)
        if len(reserveCnt)>0:
            cv2.drawContours(leftLane,[reserveCnt[0]],-1,(0,255,255),-1)
            cv2.drawContours(copy,[reserveCnt[0]],-1,(0,255,255),-1)
        
        return copy,leftLane
    def extract_left_lane2(self,pic,image):
        height,width=pic.shape
        # leftLane = np.zeros(pic.shape,dtype='uint8')
        # leftLane[height//2+10:,:width//2] = 1
        leftLane = pic.copy()
        _,contours,_ = cv2.findContours(leftLane,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)
        boundingBoxes = [(cv2.boundingRect(cnt),cv2.contourArea(cnt),cnt)for cnt in contours]
        boundingBoxes = sorted(boundingBoxes,key=lambda x:(x[0][1]+x[0][3],x[1]),reverse=True)
        # reduce noise
        copy = image.copy()
        reserveCnt = []
        for rect,area,cnt in boundingBoxes:
            # if len(reserveCnt)>0:
            #     break
            if area<200:
                continue
            elif rect[3]<100:
                continue
            else :
                reserveCnt = [rect,area,cnt]
                # self.area.append(area)
                # print('minArea',min(self.area))
                # interFlg,box = self.detect_intersection(cnt,pic.shape)
                # reserveCnt = [cnt,box]
                # if interFlg=='inter':
                #     cv2.drawContours(copy,[cnt],-1,(0,255,0),-1)
                # elif interFlg=='continue':
                #     continue
                # elif len(reserveCnt)<1:
                #     reserveCnt = [cnt,box]
                    # break
        leftLane = np.ones(pic.shape,dtype='uint8')*255
        leftLane = cv2.cvtColor(leftLane,cv2.COLOR_GRAY2BGR)
        if len(reserveCnt)>0:
            cv2.drawContours(leftLane,[reserveCnt[2]],-1,(0,255,255),-1)
            cv2.drawContours(copy,[reserveCnt[2]],-1,(0,255,255),-1)
        
        return copy,leftLane
    def extract_right_lane(self,pic,image):
        height,width=pic.shape
        # leftLane = np.zeros(pic.shape,dtype='uint8')
        # leftLane[height//2+10:,:width//2] = 1
        leftLane = pic.copy()
        _,contours,_ = cv2.findContours(leftLane,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)
        boundingBoxes = [(cv2.boundingRect(cnt),cv2.contourArea(cnt),cnt)for cnt in contours]
        boundingBoxes = sorted(boundingBoxes,key=lambda x:(x[0][1]+x[0][3],x[1]),reverse=True)
        # reduce noise
        copy = image.copy()
        reserveCnt = []
        for rect,area,cnt in boundingBoxes:
            # if len(reserveCnt)>0:
            #     break
            if area<200:
                continue
            else:
                # self.area.append(area)
                # print('minArea',min(self.area))
                interFlg,box = self.detect_intersection(cnt,pic.shape)
                if interFlg=='inter':
                    cv2.drawContours(copy,[cnt],-1,(0,255,0),-1)
                elif interFlg=='continue':
                    continue
                elif len(reserveCnt)<1:
                    reserveCnt = [cnt,box]
                    # break
        leftLane = np.ones(pic.shape,dtype='uint8')*255
        leftLane = cv2.cvtColor(leftLane,cv2.COLOR_GRAY2BGR)
        if len(reserveCnt)>0:
            cv2.drawContours(leftLane,[reserveCnt[0]],-1,(0,255,255),-1)
            cv2.drawContours(copy,[reserveCnt[0]],-1,(0,255,255),-1)
        
        return copy,leftLane
    def calculate_slope(self,img,pic):
        edges = cv2.Canny(img,100,200)
        lines = cv2.HoughLinesP(edges,1,np.pi/180,10,minLineLength=45,maxLineGap=20)
        if lines is None:
            return None
        slopes = []
        #print(lines)
        for i in range(len(lines)):
            if i > 5:
                break
            for x1,y1,x2,y2 in lines[i]:
                '''a = np.cos(theta)
                b = np.sin(theta)
                x0 = a*rho
                y0 = b*rho
                x1 = x0 + 1000*(-b)
                y1 = y0 + 1000*(a)
                x2 = x0 - 1000*(-b)
                y2 = y0 - 1000*(a)
                '''             
                if x1 != x2:
                    slope = (y2-y1)/(x2-x1)
                    slopes.append(slope)
                cv2.line(pic,(int(x1),int(y1)),(int(x2),int(y2)),(0,255,0),3)
        if len(slopes) == 0:
            print(0)
            return 0 
        mean = sum(slopes)/len(slopes)
        #print(mean)
        actan = math.degrees(math.atan(mean))
        sign = 0
        if actan < 0:
            sign= -1
        else:
            sign = 1
        deg = 90 - math.fabs(actan)
        #print(deg*sign)

        return deg*sign
        
    def getsignal(self,cmd):
        print(cmd)
        if cmd == "stop" or cmd.data=="stop":
            rospy.loginfo("stop. cmd_vel will be 0")

            twist = Twist()
            twist.linear.x = 0
            twist.linear.y = 0
            twist.linear.z = 0
            twist.angular.x = 0
            twist.angular.y = 0
            twist.angular.z = 0
            self.pub_cmd_vel.publish(twist)
            self.stop = True
        elif cmd == "start" or cmd.data=="start":
            rospy.loginfo("restart. the bot would run again")
            self.stop = False    

    def intersection(self,mask,image):
        intersection = mask.copy()
        _,contours,_ = cv2.findContours(intersection,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)
        # test = np.zeros(image.shape,dtype='uint8')
        # cv2.drawContours(test,contours,-1,(255,255,255),-1)
        # cv2.imshow('test',mask)
        # cv2.waitKey()
        boundingBoxes = [(cv2.boundingRect(cnt),cv2.contourArea(cnt),cnt)for cnt in contours]
        boundingBoxes = sorted(boundingBoxes,key=lambda x:(x[0][2],x[0][1]+x[0][3],x[1]),reverse=True)
        copy = image.copy()
        reserveCnt = []
        for rect,area,cnt in boundingBoxes:
            # if len(reserveCnt)>0:
            #     break
            print(rect,area)
            if area<100:
                continue
            elif rect[2]<60:
                continue
            elif rect[1]+rect[3]<180 or rect[1]<140:
                continue
            else :
                reserveCnt = [cnt]
                break
        intersection = np.ones(mask.shape,dtype='uint8')*255
        intersection = cv2.cvtColor(intersection,cv2.COLOR_GRAY2BGR)
        if len(reserveCnt)>0:
            cv2.drawContours(intersection,reserveCnt,-1,(0,0,255),-1)
            cv2.drawContours(copy,reserveCnt,-1,(0,0,255),-1)
            cv2.putText(image,"INTERSECTION", (100, 100), cv2.FONT_HERSHEY_DUPLEX, 0.5, (0, 0, 255))
            self.pub_image_intersection.publish(self.cvBridge.cv2_to_imgmsg(image, "bgr8"))
            rospy.loginfo("INTERSECTION")
        
        return copy,intersection

    def cbFindLane(self, image_msg):
        # TODO: mov_avg error
        #print("start")
        # Change the frame rate by yourself. Now, it is set to 1/3 (10fps). 
        # Unappropriate value of frame rate may cause huge delay on entire recognition process.
        # This is up to your computer's operating power.
        if self.counter % 3 != 0:
            self.counter += 1
            return
        else:
            self.counter = 1
        #print("start")t.linear.x
        if self.sub_image_type == "compressed":
            #converting compressed image to opencv image
            np_arr = np.fromstring(image_msg.data, np.uint8)
            cv_image = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
        elif self.sub_image_type == "raw":
            cv_image = self.cvBridge.imgmsg_to_cv2(image_msg, "bgr8")
        #print("cv_image is imported")
        #print(cv_image.shape)
        #self.pub_image_lane.publish(self.cvBridge.cv2_to_compressed_imgmsg(cv_image, "jpg"))
        #self.pub_image_lane.publish(self.cvBridge.cv2_to_imgmsg(cv_image, "bgr8"))

        #return #TEST
        #print(cv_image.shape)
        #half_img = self.processimg(cv_image) ####NEED THIS
        #print("cv_image is processed")
        '''if half_img is None:
        print("No lines detected")
        return''' 
        # cv2.imshow("BIRD",cv_image)
        # cv2.waitKey()
        #self.pub_image_lane.publish(self.cvBridge.cv2_to_imgmsg(half_img, "bgr8"))
        #self.pub_image_lane.publish(self.cvBridge.cv2_to_compressed_imgmsg(half_img, "jpg"))
        # self.pub_image_cv_image.publish(self.cvBridge.cv2_to_compressed_imgmsg(cv_image, "jpg"))
        
        height,width = cv_image.shape[0],cv_image.shape[1]
        mask0 = self.extract_white(cv_image)
        mask = mask0.copy()
        mask[:,width//2:]=0
        cv_image,cal = self.extract_left_lane2(mask,cv_image)
        mask = self.extract_white(cv_image)
        mask[:,:width//2]=0
        cv_image[mask>0]=255
        mask0[:,:width//3]=0
        mask0[:,width//3*2:]=0
        cv_image,cal = self.intersection(mask0,cv_image)
        # cv_image,cal = self.extract_right_lane(mask,cv_image)
        # cv2.imshow("BIRD",cv_image)
        # cv_image[:height//2+20,:,:]=0
        # # print(cv_image.shape)
        # cv2.imshow("BIRD",cv_image)
        # cv2.waitKey()
        # # cv2.destroyAllWindows()
        # mask[:height//2+20,:]=0
        # mask[:,:width//2]=0
        # mask=cv2.cvtColor(mask,cv2.COLOR_GRAY2BGR)
        yellow_fraction, cv_yellow_lane = self.maskYellowLane(cv_image)
        white_fraction, cv_white_lane = self.maskWhiteLane(cv_image)
        # cv2.imshow('cv_yellow_lane',cv_yellow_lane)
        # cv2.imshow('cv_white_lane',cv_white_lane)
        # cv2.waitKey()
        # print(yellow_fraction,white_fraction)
        try:
            if yellow_fraction > 1000:
                self.left_fitx, self.left_fit = self.fit_from_lines(self.left_fit, cv_yellow_lane)
                self.mov_avg_left = np.append(self.mov_avg_left,np.array([self.left_fit]), axis=0)

            if white_fraction > 200:
                self.right_fitx, self.right_fit = self.fit_from_lines(self.right_fit, cv_white_lane)
                self.mov_avg_right = np.append(self.mov_avg_right,np.array([self.right_fit]), axis=0)
        except:
            if yellow_fraction > 1000:
                self.left_fitx, self.left_fit = self.sliding_windown(cv_yellow_lane, 'left')
                self.mov_avg_left = np.array([self.left_fit])

            if white_fraction > 200:
                self.right_fitx, self.right_fit = self.sliding_windown(cv_white_lane, 'right')
                self.mov_avg_right = np.array([self.right_fit])

        MOV_AVG_LENGTH = 5

        self.left_fit = np.array([np.mean(self.mov_avg_left[::-1][:, 0][0:MOV_AVG_LENGTH]),
                            np.mean(self.mov_avg_left[::-1][:, 1][0:MOV_AVG_LENGTH]),
                            np.mean(self.mov_avg_left[::-1][:, 2][0:MOV_AVG_LENGTH])])
        self.right_fit = np.array([np.mean(self.mov_avg_right[::-1][:, 0][0:MOV_AVG_LENGTH]),
                            np.mean(self.mov_avg_right[::-1][:, 1][0:MOV_AVG_LENGTH]),
                            np.mean(self.mov_avg_right[::-1][:, 2][0:MOV_AVG_LENGTH])])

        if self.mov_avg_left.shape[0] > 1000:
            self.mov_avg_left = self.mov_avg_left[0:MOV_AVG_LENGTH]

        if self.mov_avg_right.shape[0] > 1000:
            self.mov_avg_right = self.mov_avg_right[0:MOV_AVG_LENGTH]

        self.make_lane(cv_image, white_fraction, yellow_fraction)
        
        # pic,cal = self.extract_left_lane(self.extract_white(cv_image),cv_image)
        # cv2.imshow("BIRD",pic)
        # cv2.waitKey()

        # # cv2.imwrite('/home/rsa/Pictures/'+str(self.frame_count)+'_pic.jpg',pic)
        
        # self.frame_count+=1
        # # self.pub_image_lane.publish(self.cvBridge.cv2_to_imgmsg(pic,"bgr8"))
        # pic = self.birdview(pic)
        
        # if cal is not None and pic is not None:
        #     ratio= self.calculate_slope(self.birdview(cal),pic)
        # else:
        #     pass # 
        # '''if slope is None:
        #     #U CANT SEE ANY LiNES SO tURN LEFT A LITTlE BIT HERE
        #     pass
        # else:'''
        # #print(ratio)
        
        # if ratio == 90:
        #     #error ratio should not be 90
        #     return

        # self.stop=False
        # error = 0
        # ##publish velocity here
        # if not self.stop:
        #     angular = self.max_turn * ratio / 90
        #     velocity = self.max_vel * (1 - math.fabs(angular) / self.max_turn)
        #     twist = Twist()
        #     twist.linear.x = max(velocity, self.min_speed) #SET 0.04 TO BE MIN_SPEED
        #     twist.linear.y = 0
        #     twist.linear.z = 0
        #     twist.angular.x = 0
        #     twist.angular.y = 0
        #     twist.angular.z = angular - error   #-max(angular_z, -2.0) if angular_z < 0 else -min(angular_z, 2.0)
        #     self.twistPub.publish(twist)
        #     print("linear: ","{:.3f}".format(twist.linear.x),"  angular : " , "{:.2f}".format(twist.angular.z))
        



        # #pic = self.birdview(pic)
        # #cv2.imshow("input",cv_image)
        # #cv2.waitKey()
        # self.pub_image_lane.publish(self.cvBridge.cv2_to_imgmsg(pic,"bgr8")) #<--TEST IN GAZEBO

        # #return #test in gazebo
        # #print("image is PUBLISHED")
        # #cv_image = half_img      ##############NEED THIS
        # #print(cv_image.shape)
        # return

        # # find White and Yellow Lanes
        # white_fraction, cv_white_lane = self.maskWhiteLane(cv_image)
        # yellow_fraction, cv_yellow_lane = self.maskYellowLane(cv_image)
        # #print(yellow_fraction,white_fraction)
        
        # try:
        #     if yellow_fraction > 1000:
        #         self.left_fitx, self.left_fit = self.fit_from_lines(self.left_fit, cv_yellow_lane)
        #         self.mov_avg_left = np.append(self.mov_avg_left,np.array([self.left_fit]), axis=0)

        #     if white_fraction > 1000:
        #         self.right_fitx, self.right_fit = self.fit_from_lines(self.right_fit, cv_white_lane)
        #         self.mov_avg_right = np.append(self.mov_avg_right,np.array([self.right_fit]), axis=0)
        # except:
        #     if yellow_fraction > 1000:
        #         self.left_fitx, self.left_fit = self.sliding_windown(cv_yellow_lane, 'left')
        #         self.mov_avg_left = np.array([self.left_fit])

        #     if white_fraction > 1000:
        #         self.right_fitx, self.right_fit = self.sliding_windown(cv_white_lane, 'right')
        #         self.mov_avg_right = np.array([self.right_fit])

        # #print(self.left_fitx)
        # MOV_AVG_LENGTH = 5
        
        # self.left_fit = np.array([np.mean(self.mov_avg_left[::-1][:, 0][0:MOV_AVG_LENGTH]),
        #                     np.mean(self.mov_avg_left[::-1][:, 1][0:MOV_AVG_LENGTH]),
        #                     np.mean(self.mov_avg_left[::-1][:, 2][0:MOV_AVG_LENGTH])])
        # '''
        # self.right_fit = np.array([np.mean(self.mov_avg_right[::-1][:, 0][0:MOV_AVG_LENGTH]),
        #                     np.mean(self.mov_avg_right[::-1][:, 1][0:MOV_AVG_LENGTH]),
        #                     np.mean(self.mov_avg_right[::-1][:, 2][0:MOV_AVG_LENGTH])])
        # '''
        # #print(self.mov_avg_left.shape[0])
        # if self.mov_avg_left.shape[0] > 100:
        #     self.mov_avg_left = self.mov_avg_left[0:MOV_AVG_LENGTH]

        # '''if self.mov_avg_right.shape[0] > 1000:
        #     self.mov_avg_right = self.mov_avg_right[0:MOV_AVG_LENGTH]
        # '''
        # self.make_lane(cv_image, white_fraction, yellow_fraction)
        
    def maskWhiteLane(self, image):
        # Convert BGR to HSV
        #image = image[:,image.shape[1]/2:,:] #extracting the right part of the image
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)


        Hue_l = self.hue_white_l
        Hue_h = self.hue_white_h
        Saturation_l = self.saturation_white_l
        Saturation_h = self.saturation_white_h
        Lightness_l = self.lightness_white_l
        Lightness_h = self.lightness_white_h

        # define range of white color in HSV
        lower_white = np.array([Hue_l, Saturation_l, Lightness_l])
        upper_white = np.array([Hue_h, Saturation_h, Lightness_h])

        # Threshold the HSV image to get only white colors
        mask = cv2.inRange(hsv, lower_white, upper_white)

        # Bitwise-AND mask and original image
        res = cv2.bitwise_and(image, image, mask = mask)

        fraction_num = np.count_nonzero(mask)

        if self.is_calibration_mode == False:
            if fraction_num > 35000:
                if self.lightness_white_l < 250:
                    self.lightness_white_l += 5
            elif fraction_num < 5000:
                if self.lightness_white_l > 50:
                    self.lightness_white_l -= 5

        how_much_short = 0

        for i in range(0, self.img_len):
            if np.count_nonzero(mask[i,::]) > 0:
                how_much_short += 1

        how_much_short = self.img_len - how_much_short

        if how_much_short > 100:
            if self.reliability_white_line >= 5:
                self.reliability_white_line -= 5
        elif how_much_short <= 100:
            if self.reliability_white_line <= 99:
                self.reliability_white_line += 5

        msg_white_line_reliability = UInt8()
        msg_white_line_reliability.data = self.reliability_white_line
        self.pub_white_line_reliability.publish(msg_white_line_reliability)

        if self.is_calibration_mode == True:
            if self.pub_image_type == "compressed":
                # publishes white lane filtered image in compressed type
                self.pub_image_white_lane.publish(self.cvBridge.cv2_to_compressed_imgmsg(mask, "jpg"))

            elif self.pub_image_type == "raw":
                # publishes white lane filtered image in raw type
                self.pub_image_white_lane.publish(self.cvBridge.cv2_to_imgmsg(mask, "bgr8"))

        return fraction_num, mask

    def maskYellowLane(self, image):
        # Convert BGR to HSV
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

        Hue_l = self.hue_yellow_l
        Hue_h = self.hue_yellow_h
        Saturation_l = self.saturation_yellow_l
        Saturation_h = self.saturation_yellow_h
        Lightness_l = self.lightness_yellow_l
        Lightness_h = self.lightness_yellow_h

        # define range of yellow color in HSV
        lower_yellow = np.array([Hue_l, Saturation_l, Lightness_l])
        upper_yellow = np.array([Hue_h, Saturation_h, Lightness_h])

        # Threshold the HSV image to get only yellow colors
        mask = cv2.inRange(hsv, lower_yellow, upper_yellow)

        # Bitwise-AND mask and original image
        res = cv2.bitwise_and(image, image, mask = mask)

        fraction_num = np.count_nonzero(mask)

        if self.is_calibration_mode == False:
            if fraction_num > 35000:
                if self.lightness_yellow_l < 250:
                    self.lightness_yellow_l += 20
            elif fraction_num < 5000:
                if self.lightness_yellow_l > 90:
                    self.lightness_yellow_l -= 20

        how_much_short = 0

        for i in range(0, self.img_len):
            if np.count_nonzero(mask[i,::]) > 0:
                how_much_short += 1
        
        how_much_short = self.img_len - how_much_short

        if how_much_short > 100:
            if self.reliability_yellow_line >= 5:
                self.reliability_yellow_line -= 5
        elif how_much_short <= 100:
            if self.reliability_yellow_line <= 99:
                self.reliability_yellow_line += 5

        msg_yellow_line_reliability = UInt8()
        msg_yellow_line_reliability.data = self.reliability_yellow_line
        self.pub_yellow_line_reliability.publish(msg_yellow_line_reliability)

        if self.is_calibration_mode == True:
            if self.pub_image_type == "compressed":
                # publishes yellow lane filtered image in compressed type
                self.pub_image_yellow_lane.publish(self.cvBridge.cv2_to_compressed_imgmsg(mask, "jpg"))

            elif self.pub_image_type == "raw":
                # publishes yellow lane filtered image in raw type
                self.pub_image_yellow_lane.publish(self.cvBridge.cv2_to_imgmsg(mask, "bgr8"))

        return fraction_num, mask

    def fit_from_lines(self, lane_fit, image):
        nonzero = image.nonzero()
        nonzeroy = np.array(nonzero[0])
        nonzerox = np.array(nonzero[1])
        margin = 100
        lane_inds = ((nonzerox > (lane_fit[0] * (nonzeroy ** 2) + lane_fit[1] * nonzeroy + lane_fit[2] - margin)) & (
        nonzerox < (lane_fit[0] * (nonzeroy ** 2) + lane_fit[1] * nonzeroy + lane_fit[2] + margin)))

        # Again, extract line pixel positions
        x = nonzerox[lane_inds]
        y = nonzeroy[lane_inds]

        # Fit a second order polynomial to each
        lane_fit = np.polyfit(y, x, 2)

        # Generate x and y values for plotting
        ploty = np.linspace(0, image.shape[0] - 1, image.shape[0])
        lane_fitx = lane_fit[0] * ploty ** 2 + lane_fit[1] * ploty + lane_fit[2]
            
        return lane_fitx, lane_fit

    def sliding_windown(self, img_w, left_or_right):
        histogram = np.sum(img_w[img_w.shape[0] / 2:, :], axis=0)

        # Create an output image to draw on and visualize the result
        out_img = np.dstack((img_w, img_w, img_w)) * 255
        #out_image = 
        # Find the peak of the left and right halves of the histogram
        # These will be the starting point for the left and right lines
        midpoint = np.int(histogram.shape[0] / 2)

        if left_or_right == 'left':
            lane_base = np.argmax(histogram[:midpoint])
            #print("lane_base : ",lane_base)
        elif left_or_right == 'right':
            lane_base = np.argmax(histogram[midpoint:]) + midpoint

        # Choose the number of sliding windows
        nwindows = 20

        # Set height of windows
        window_height = np.int(img_w.shape[0] / nwindows)

        # Identify the x and y positions of all nonzero pixels in the image
        nonzero = img_w.nonzero()
        nonzeroy = np.array(nonzero[0])
        nonzerox = np.array(nonzero[1])
        #print(nonzerox,nonzeroy)
        # Current positions to be updated for each window
        x_current = lane_base

        # Set the width of the windows +/- margin
        margin = 30

        # Set minimum number of pixels found to recenter window
        minpix = 30

        # Create empty lists to receive lane pixel indices
        lane_inds = []

        # Step through the windows one by one
        for window in range(nwindows):
            # Identify window boundaries in x and y
            win_y_low = img_w.shape[0] - (window + 1) * window_height
            win_y_high = img_w.shape[0] - window * window_height
            win_x_low = x_current - margin
            win_x_high = x_current + margin

            # Draw the windows on the visualization image
            cv2.rectangle(out_img, (win_x_low, win_y_low), (win_x_high, win_y_high), (0, 255, 0), 2)

            # Identify the nonzero pixels in x and y within the window
            good_lane_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_x_low) & (
                nonzerox < win_x_high)).nonzero()[0]

            # Append these indices to the lists
            lane_inds.append(good_lane_inds)

            # If you found > minpix pixels, recenter next window on their mean position
            if len(good_lane_inds) > minpix:
                x_current = np.int(np.mean(nonzerox[good_lane_inds]))

        # Concatenate the arrays of indices
        lane_inds = np.concatenate(lane_inds)

        # Extract line pixel positions
        x = nonzerox[lane_inds]
        y = nonzeroy[lane_inds]
        #print(x,y)
        ##############test####################
        #lane_fit = np.polyfit(y, x, 2)
        #print(lane_fit)
        #return None,None
        ##################################3

        # Fit a second order polynomial to each
        try:
            lane_fit = np.polyfit(y, x, 2)
            self.lane_fit_bef = lane_fit
            
        except:
            lane_fit = self.lane_fit_bef

        # Generate x and y values for plotting
        ploty = np.linspace(0, img_w.shape[0] - 1, img_w.shape[0])
        lane_fitx = lane_fit[0] * ploty ** 2 + lane_fit[1] * ploty + lane_fit[2]

        return lane_fitx, lane_fit

    def make_lane(self, cv_image, white_fraction, yellow_fraction):
        # Create an image to draw the lines on
        warp_zero = np.zeros((cv_image.shape[0], cv_image.shape[1], 1), dtype=np.uint8)

        color_warp = np.dstack((warp_zero, warp_zero, warp_zero))
        color_warp_lines = np.dstack((warp_zero, warp_zero, warp_zero))

        ploty = np.linspace(0, cv_image.shape[0] - 1, cv_image.shape[0])

        if yellow_fraction > 1000:
            pts_left = np.array([np.flipud(np.transpose(np.vstack([self.left_fitx, ploty])))])
            cv2.polylines(color_warp_lines, np.int_([pts_left]), isClosed=False, color=(0, 0, 255), thickness=25)

        if white_fraction > 200:
            pts_right = np.array([np.transpose(np.vstack([self.right_fitx, ploty]))])
            cv2.polylines(color_warp_lines, np.int_([pts_right]), isClosed=False, color=(255, 255, 0), thickness=25)
        
        self.is_center_x_exist = True

        if self.reliability_white_line > 50 and self.reliability_yellow_line > 50:   
            if white_fraction > 200 and yellow_fraction > 1000:
                centerx = np.mean([self.left_fitx, self.right_fitx], axis=0)
                pts = np.hstack((pts_left, pts_right))
                pts_center = np.array([np.transpose(np.vstack([centerx, ploty]))])

                cv2.polylines(color_warp_lines, np.int_([pts_center]), isClosed=False, color=(0, 255, 255), thickness=12)

                # Draw the lane onto the warped blank image
                cv2.fillPoly(color_warp, np.int_([pts]), (0, 255, 0))

            if white_fraction > 200 and yellow_fraction <= 1000:
                centerx = np.subtract(self.right_fitx, 320)
                pts_center = np.array([np.transpose(np.vstack([centerx, ploty]))])

                cv2.polylines(color_warp_lines, np.int_([pts_center]), isClosed=False, color=(0, 255, 255), thickness=12)

            if white_fraction <= 200 and yellow_fraction > 1000:
                centerx = np.add(self.left_fitx, 320)
                pts_center = np.array([np.transpose(np.vstack([centerx, ploty]))])

                cv2.polylines(color_warp_lines, np.int_([pts_center]), isClosed=False, color=(0, 255, 255), thickness=12)

        elif self.reliability_white_line <= 50 and self.reliability_yellow_line > 50:
            centerx = np.add(self.left_fitx, 320)
            pts_center = np.array([np.transpose(np.vstack([centerx, ploty]))])

            cv2.polylines(color_warp_lines, np.int_([pts_center]), isClosed=False, color=(0, 255, 255), thickness=12)

        elif self.reliability_white_line > 50 and self.reliability_yellow_line <= 50:
            centerx = np.subtract(self.right_fitx, 320)
            pts_center = np.array([np.transpose(np.vstack([centerx, ploty]))])

            cv2.polylines(color_warp_lines, np.int_([pts_center]), isClosed=False, color=(0, 255, 255), thickness=12)

        else:
            self.is_center_x_exist = False
            # TODO: stop
            pass

        # Combine the result with the original image
        final = cv2.addWeighted(cv_image, 1, color_warp, 0.2, 0)
        final = cv2.addWeighted(final, 1, color_warp_lines, 1, 0)

        if self.pub_image_type == "compressed":
            if self.is_center_x_exist == True:
                # publishes lane center
                msg_desired_center = Float64()
                msg_desired_center.data = centerx.item(140)
                self.pub_lane.publish(msg_desired_center)

            self.pub_image_lane.publish(self.cvBridge.cv2_to_compressed_imgmsg(final, "jpg"))

        elif self.pub_image_type == "raw":
            if self.is_center_x_exist == True:
                # publishes lane center
                msg_desired_center = Float64()
                msg_desired_center.data = centerx.item(140)
                self.pub_lane.publish(msg_desired_center)

            self.pub_image_lane.publish(self.cvBridge.cv2_to_imgmsg(final, "bgr8"))

    def main(self):
        rospy.spin()

if __name__ == '__main__':
    rospy.init_node('detect_lane')
    node = DetectLane()
    node.main()
